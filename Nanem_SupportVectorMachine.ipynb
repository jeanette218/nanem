{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nanem-SupportVectorMachine.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimimumemo/nanem/blob/main/Nanem_SupportVectorMachine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maU_FGrB8EIC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95088258-9254-456a-e6dd-5420663c58e0"
      },
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py:1761: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKO7mCar-cUg"
      },
      "source": [
        "#Convolutional Neural Network\n",
        "\n",
        "#Importing the libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FhH-VDPg_I95",
        "outputId": "65922e99-7974-4c57-f61e-3778c8aa65ee"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm7esCBb_NMM"
      },
      "source": [
        "#Part 1 - Data Preprocessing\n",
        "\n",
        "#Preprocessing the Training Set\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSYYlk2I_pVA",
        "outputId": "37ef3f19-c037-44d0-e98a-29fe51742f34"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_yH6GlD_1bc",
        "outputId": "89368063-f441-4697-fb05-b68ce7235659"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/gambar_tanah (1)/train',\n",
        "                                                 target_size = (64,64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "#Preprocessing the Test set\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/gambar_tanah (1)/test',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 228 images belonging to 2 classes.\n",
            "Found 5 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKVOBxf5FL4u"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEgz-DstFWtH"
      },
      "source": [
        "from tensorflow.keras.regularizers import l2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa4G1qjiFa2x"
      },
      "source": [
        "#Part 2 - Building the CNN\n",
        "#Initialising the CNN\n",
        "cnn = tf.keras.models.Sequential()\n",
        "\n",
        "#Step 1 - Convolution\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, \n",
        "                               padding=\"same\",\n",
        "                               kernel_size=3, \n",
        "                               activation='relu', \n",
        "                               strides=2, \n",
        "                               input_shape=[64,64, 3]))\n",
        "\n",
        "#Step 2 - Pooling\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,\n",
        "                                  strides=2))\n",
        "\n",
        "#Adding a second convolutional layer\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,\n",
        "                               padding='same',\n",
        "                               kernel_size=3,\n",
        "                               activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,\n",
        "                                  strides=2))\n",
        "\n",
        "#Step 3 - Flattening\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "\n",
        "#Step 4 - Full Connection\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jipuxuhNHDsv"
      },
      "source": [
        "##for multiclassification\n",
        "cnn.add(Dense(2, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation='softmax'))\n",
        "cnn.compile(optimizer='adam', loss='squared_hinge', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibJU4meDHhQX",
        "outputId": "1a8b1ba7-8a05-4c7f-f44c-683ae93b8cd2"
      },
      "source": [
        "cnn.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 516       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 10        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 12        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 10        \n",
            "=================================================================\n",
            "Total params: 272,964\n",
            "Trainable params: 272,964\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHD4eOAFHj6f",
        "outputId": "68c2f765-eb7c-42a8-aec4-83fb12396b47"
      },
      "source": [
        "#Part 3 -Training the CNN\n",
        "\n",
        "#Compiling the CNN\n",
        "cnn.compile(optimizer='adam', loss='hinge', metrics=['accuracy'])\n",
        "\n",
        "#Training the CNN on the Training set and evaluating it on the Test set\n",
        "r=cnn.fit(x=training_set, validation_data=test_set,\n",
        "          epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 4s 518ms/step - loss: 1.1275 - accuracy: 0.3094 - val_loss: 1.0677 - val_accuracy: 0.6000\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 3s 409ms/step - loss: 1.1186 - accuracy: 0.3086 - val_loss: 1.0638 - val_accuracy: 0.6000\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 3s 424ms/step - loss: 1.1092 - accuracy: 0.3135 - val_loss: 1.0605 - val_accuracy: 0.6000\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 3s 436ms/step - loss: 1.1021 - accuracy: 0.3101 - val_loss: 1.0579 - val_accuracy: 0.6000\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 3s 414ms/step - loss: 1.0972 - accuracy: 0.2917 - val_loss: 1.0558 - val_accuracy: 0.6000\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 3s 406ms/step - loss: 1.0889 - accuracy: 0.2995 - val_loss: 1.0539 - val_accuracy: 0.6000\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 3s 475ms/step - loss: 1.0817 - accuracy: 0.3045 - val_loss: 1.0525 - val_accuracy: 0.6000\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 3s 413ms/step - loss: 1.0722 - accuracy: 0.3474 - val_loss: 1.0513 - val_accuracy: 0.6000\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 3s 419ms/step - loss: 1.0690 - accuracy: 0.3211 - val_loss: 1.0506 - val_accuracy: 0.6000\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 3s 403ms/step - loss: 1.0671 - accuracy: 0.2612 - val_loss: 1.0501 - val_accuracy: 0.6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQla2aEQIFbN"
      },
      "source": [
        "#plot the loss\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUxfTm1KV4F-"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.python.platform\n",
        "from tensorflow.python.platform import gfile\n",
        "import numpy as np\n",
        " \n",
        "def create_graph(model_path):\n",
        "    \"\"\"\n",
        "    create_graph loads the inception model to memory, should be called before\n",
        "    calling extract_features.\n",
        " \n",
        "    model_path: path to inception model in protobuf form.\n",
        "    \"\"\"\n",
        "    with gfile.FastGFile(model_path, 'rb') as f:\n",
        "        graph_def = tf.compat.v1.GraphDef()\n",
        "        graph_def.ParseFromString(f.read())\n",
        "        _ = tf.import_graph_def(graph_def, name='')\n",
        " \n",
        " \n",
        "def extract_features(image_paths, verbose=False):\n",
        "    \"\"\"\n",
        "    extract_features computed the inception bottleneck feature for a list of images\n",
        " \n",
        "    image_paths: array of image path\n",
        "    return: 2-d array in the shape of (len(image_paths), 2048)\n",
        "    \"\"\"\n",
        "    feature_dimension = 2048\n",
        "    features = np.empty((len(image_paths), feature_dimension))\n",
        " \n",
        "    with tf.compat.v1.Session() as sess:\n",
        "        flattened_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
        " \n",
        "        for i, image_path in enumerate(image_paths):\n",
        "            if verbose:\n",
        "                print('Processing %s...' % (image_path))\n",
        " \n",
        "            if not gfile.Exists(image_path):\n",
        "                tf.logging.fatal('File does not exist %s', image)\n",
        " \n",
        "            image_data = gfile.FastGFile(image_path, 'rb').read()\n",
        "            feature = sess.run(flattened_tensor, {\n",
        "                'DecodeJpeg/contents:0': image_data\n",
        "            })\n",
        "            features = np.squeeze(feature)\n",
        " \n",
        "    return features "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "OxonNq4xiNDk",
        "outputId": "5f0cd178-ae21-4bcc-f73d-b2a75be8b012"
      },
      "source": [
        "extract_features('/content/drive/MyDrive/gambar_tanah')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e47294d8fab3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/gambar_tanah'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-20b622b25c64>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(image_paths, verbose)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mflattened_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pool_3:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3900\u001b[0m       raise TypeError(\"Tensor names are strings (or similar), not %s.\" %\n\u001b[1;32m   3901\u001b[0m                       type(name).__name__)\n\u001b[0;32m-> 3902\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3904\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_tensor_by_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3725\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3726\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3728\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3766\u001b[0m           raise KeyError(\"The name %s refers to a Tensor which does not \"\n\u001b[1;32m   3767\u001b[0m                          \u001b[0;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3768\u001b[0;31m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[1;32m   3769\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3770\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"The name 'pool_3:0' refers to a Tensor which does not exist. The operation, 'pool_3', does not exist in the graph.\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLj708qdiUIB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}